{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEYqZNNvihEg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install datasets transformers[tf,torch,sentencepiece,vision,optuna,sklearn,onnxruntime]==4.11.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Morn1jEihEm"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from utils import *\n",
        "setup_chapter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX2FearxihEr"
      },
      "source": [
        "In this book we will demonstrate how you can run the example from the book in Amazon SageMaker. \n",
        "\n",
        "The SageMaker notebook uses an AWS IAM role to access AWS resources such as Amazon S3 bucket.\n",
        "You created this role during the notebook creation process described in the README.md in SageMaker/README.md.\n",
        "In the AWS IAM service you are able to review the access policy and you can modify it.\n",
        "\n",
        "In the next cell we will check an Amazon S3 bucket exists and create a new one if not. In addition we'll get the SageMaker role and session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGtSjUFihEy",
        "outputId": "23e07042-8320-46ed-df5e-204881803d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sagemaker\n",
            "  Downloading sagemaker-2.151.0.tar.gz (747 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.0/748.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting attrs<23,>=20.3.0 (from sagemaker)\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.26.28 (from sagemaker)\n",
            "  Downloading boto3-1.26.124-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.2.1)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4.0,>=3.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.20.3)\n",
            "Collecting protobuf3-to-dict<1.0,>=0.1.5 (from sagemaker)\n",
            "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting smdebug_rulesconfig==1.0.1 (from sagemaker)\n",
            "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting importlib-metadata<5.0,>=1.4.0 (from sagemaker)\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.5.3)\n",
            "Collecting pathos (from sagemaker)\n",
            "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting schema (from sagemaker)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Collecting PyYAML==5.4.1 (from sagemaker)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.3.3)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.3.0)\n",
            "Requirement already satisfied: tblib==1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.7.0)\n",
            "Collecting botocore<1.30.0,>=1.29.124 (from boto3<2.0,>=1.26.28->sagemaker)\n",
            "  Downloading botocore-1.29.124-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.26.28->sagemaker)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0,>=1.26.28->sagemaker)\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker) (2022.7.1)\n",
            "Collecting ppft>=1.7.6.6 (from pathos->sagemaker)\n",
            "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.6 (from pathos->sagemaker)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.2 (from pathos->sagemaker)\n",
            "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.14 (from pathos->sagemaker)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->sagemaker) (0.6.0.post1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.124->boto3<2.0,>=1.26.28->sagemaker) (1.26.15)\n",
            "Building wheels for collected packages: sagemaker, PyYAML, protobuf3-to-dict\n",
            "  Building wheel for sagemaker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sagemaker: filename=sagemaker-2.151.0-py2.py3-none-any.whl size=1003772 sha256=6f26188bea55511e5a9029d6fadfc9872b5ade64ec6c92f708575352014d101b\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/e9/bb/01713c249d9194892f8a12bc7a02e13d3278a878638ed1fa13\n",
            "  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=e438e3d96a8dbec31d166be88c4fca5d3a7d35e8966d6dc653d4444295de3c13\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
            "  Building wheel for protobuf3-to-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4028 sha256=d849ba7676b5413818c3b15a3d709054a3ef3cf9c36c012eef3a600e5b8cf670\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/3e/42/e783cdd4e7b8fda9bfc472eeb465bc9041bda90a3dbece8d74\n",
            "Successfully built sagemaker PyYAML protobuf3-to-dict\n",
            "Installing collected packages: smdebug_rulesconfig, schema, PyYAML, protobuf3-to-dict, ppft, pox, jmespath, importlib-metadata, dill, attrs, multiprocess, botocore, s3transfer, pathos, boto3, sagemaker\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.6.0\n",
            "    Uninstalling importlib-metadata-6.6.0:\n",
            "      Successfully uninstalled importlib-metadata-6.6.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "Successfully installed PyYAML-5.4.1 attrs-22.2.0 boto3-1.26.124 botocore-1.29.124 dill-0.3.6 importlib-metadata-4.13.0 jmespath-1.0.1 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 s3transfer-0.6.0 sagemaker-2.151.0 schema-0.7.5 smdebug_rulesconfig-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sagemaker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Mm2JfKAihE2",
        "outputId": "ded8defc-a634-4120-9805-b5173dba9177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sagemaker role arn: arn:aws:iam::123456789012:role/my-sagemaker-role\n",
            "sagemaker bucket: my-sagemaker-bucket\n",
            "sagemaker session region: us-west-2\n"
          ]
        }
      ],
      "source": [
        "import sagemaker.huggingface\n",
        "import sagemaker\n",
        "\n",
        "sess = sagemaker.Session()\n",
        "# sagemaker session bucket -> used for uploading data, models and logs\n",
        "# sagemaker will automatically create this bucket if it not exists\n",
        "sagemaker_session_bucket=None\n",
        "if sagemaker_session_bucket is None and sess is not None:\n",
        "    # set to default bucket if a bucket name is not given\n",
        "    sagemaker_session_bucket = sess.default_bucket()\n",
        "\n",
        "role = sagemaker.get_execution_role()\n",
        "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
        "\n",
        "print(f\"sagemaker role arn: {role}\")\n",
        "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
        "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksDqFQ7fihE6"
      },
      "source": [
        "Now we setup a helper function to easily deploy any Hugging Face model as an endpoint on AWS SageMaker.\n",
        "We use the following function to create a HuggingFaceModel Class, where we are going to download the model from the Hugging Face hub. This class would also allow to use a trained model stored on the Amazon S3 bucket. \n",
        "Next, an endpoint will be created and this endpoint will host your model. Based on the model requirements you can choose a specific instance type which are equipped differently in memory, cpu, gpu. There are different inferences available, such as real-time, asynchronous or serverless.\n",
        "If you are not sure which inference works best for your model, you use Amazon SageMaker Inference Recommender.\n",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html \n",
        "\n",
        "To view all options see the documentation: https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html \n",
        "\n",
        "Depending on Transformer version, PyTorch/TensorFlow version and Python version, the mapping for the Hugging Face Model Class can be found here: https://huggingface.co/docs/sagemaker/reference#inference-dlc-overview \n",
        "\n",
        "To find the endpoints in the AWS Console navigate to https://console.aws.amazon.com/sagemaker/home#/endpoints \n",
        "\n",
        "Make sure to finish this notebook to delete the endpoint in the end. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "idjR3e9aihE9"
      },
      "outputs": [],
      "source": [
        "from sagemaker.huggingface.model import HuggingFaceModel\n",
        "\n",
        "def setup_endpoint(model_name, task_name):\n",
        "    # Hub Model configuration. <https://huggingface.co/models>\n",
        "    hub = {\n",
        "      'HF_MODEL_ID': model_name, # model_id from hf.co/models\n",
        "      'HF_TASK': task_name # NLP task you want to use for predictions\n",
        "    }\n",
        "\n",
        "    # create Hugging Face Model Class\n",
        "    huggingface_model = HuggingFaceModel(\n",
        "       env=hub, # configuration for loading model from Hub\n",
        "       role=role, # iam role with permissions to create an Endpoint\n",
        "       transformers_version=\"4.17.0\", # transformers version used\n",
        "       pytorch_version=\"1.10.2\", # pytorch version used\n",
        "       py_version=\"py38\" # python version used\n",
        "    )\n",
        "\n",
        "    # deploy model to SageMaker Inference\n",
        "    predictor = huggingface_model.deploy(\n",
        "       initial_instance_count=1, # how many instances used\n",
        "       instance_type=\"ml.m5.xlarge\" # instance type\n",
        "    )\n",
        "    return predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EmqQ8D1ihFA"
      },
      "source": [
        "# Hello Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQYxll1fihFC"
      },
      "source": [
        "## The Encoder-Decoder Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLS_oaG6ihFF"
      },
      "source": [
        "## Attention Mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raKiRT-2ihFH"
      },
      "source": [
        "## Transfer Learning in NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZOzPhWgihFI"
      },
      "source": [
        "## Hugging Face Transformers: Bridging the Gap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFUhNGP2ihFJ"
      },
      "source": [
        "## A Tour of Transformer Applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5ywQZQ4-ihFK"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svzgyTrTihFM"
      },
      "source": [
        "### Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "04PSl2DLihFN"
      },
      "outputs": [],
      "source": [
        "predictor = setup_endpoint('distilbert-base-uncased-finetuned-sst-2-english', 'text-classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mRiAaMLbihFO"
      },
      "outputs": [],
      "source": [
        "# example request, you always need to define \"inputs\"\n",
        "import pandas as pd\n",
        "\n",
        "# request\n",
        "outputs = predictor.predict({\"inputs\": text})\n",
        "df=pd.DataFrame(outputs)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "loyDVgozihFQ"
      },
      "outputs": [],
      "source": [
        "predictor.delete_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXS38slQihFR"
      },
      "source": [
        "### Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZYwJv5MBihFS"
      },
      "outputs": [],
      "source": [
        "predictor = setup_endpoint(\"dbmdz/bert-large-cased-finetuned-conll03-english\", \"ner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FSUdInjeihFT"
      },
      "outputs": [],
      "source": [
        "outputs = predictor.predict({\"inputs\": text, \"parameters\": {\"aggregation_strategy\": \"simple\"}})\n",
        "df=pd.DataFrame(outputs)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oZ7gB1CsihFU"
      },
      "outputs": [],
      "source": [
        "predictor.delete_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St-N5yfPihFV"
      },
      "source": [
        "### Question Answering "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rf3zh82jihFW"
      },
      "outputs": [],
      "source": [
        "predictor = setup_endpoint(\"distilbert-base-cased-distilled-squad\", 'question-answering')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X3NbyyT-ihFY"
      },
      "outputs": [],
      "source": [
        "question = \"What does the customer want?\"\n",
        "\n",
        "outputs = predictor.predict({\"inputs\": {\n",
        "    \"question\": question,\n",
        "    \"context\": text\n",
        "    }\n",
        "})\n",
        "\n",
        "df=pd.DataFrame([outputs])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_e9h6dDVihFZ"
      },
      "outputs": [],
      "source": [
        "predictor.delete_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1NBJesAihFZ"
      },
      "source": [
        "### Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nHZTNI5aihFa"
      },
      "outputs": [],
      "source": [
        "predictor = setup_endpoint(\"sshleifer/distilbart-cnn-12-6\", 'summarization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeHPO9vvihFa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = predictor.predict({\"inputs\": text,\n",
        "                             \"parameters\": {\n",
        "                                 \"max_length\":45,\n",
        "                                 \"clean_up_tokenization_spaces\":True\n",
        "                                 }\n",
        "                            })\n",
        "print(outputs[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEcduSEhjpTN",
        "outputId": "f6628268-35b8-4260-c69e-bdd235dd038b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Amazon, I ordered an Optimus Prime AF online from Germany, but received a Megatron AF instead. As a lifelong enemy of the Decepticons, I need an exchange of Megatron for the correct figure. I have included copies of my purchase records and look forward to hearing from you soon.Sincerely, Bumblebee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdblkRfGihFb"
      },
      "outputs": [],
      "source": [
        "predictor.delete_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPCoygj-ihFc"
      },
      "source": [
        "### Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atXqxegtihFc"
      },
      "outputs": [],
      "source": [
        "predictor = setup_endpoint(\"Helsinki-NLP/opus-mt-en-de\", \"translation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tddNbbqpihFd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = predictor.predict({\"inputs\": text,\n",
        "                             \"parameters\": {\n",
        "                                 \"min_length\":100,\n",
        "                                 \"clean_up_tokenization_spaces\":True\n",
        "                                 }\n",
        "                            })\n",
        "print(outputs[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzThvIraj_BL",
        "outputId": "c49f3151-eb98-48ce-9cf0-5249df26036f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sehr geehrtes Amazon, ich habe eine Optimus Prime AF online aus Deutschland bestellt, habe jedoch stattdessen eine Megatron AF erhalten. Als lebenslanger Feind der Decepticons benötige ich einen Umtausch von Megatron gegen die richtige Figur. Ich habe Kopien meiner Kaufaufzeichnungen beigefügt und freue mich auf Ihre baldige Antwort.Mit freundlichen Grüßen, Bumblebee.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzHt85uRihFe"
      },
      "outputs": [],
      "source": [
        "predictor.delete_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4dQVAKcihFf"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFqhRCFZihFg"
      },
      "outputs": [],
      "source": [
        "predictor = setup_endpoint(\"gpt2\", 'text-generation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhVcpLCrihFg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
        "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
        "\n",
        "outputs = predictor.predict({\"inputs\": prompt,\n",
        "                             \"parameters\": {\n",
        "                                 \"max_length\":200\n",
        "                                 }\n",
        "                            })\n",
        "print(outputs[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkKtZqXFkrCv",
        "outputId": "765f9a3a-2485-4cc4-fd1e-a88a1e5fd354"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thank you for reaching out to us, Bumblebee. We're sorry to hear about the mix-up with your order, and we understand how frustrating this can be. Please provide us with your order number and any other relevant information so we can investigate the issue and find a solution for you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f85PhOKgihFh"
      },
      "outputs": [],
      "source": [
        "predictor.delete_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wOKv6OAihFi"
      },
      "source": [
        "## The Hugging Face Ecosystem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvjRaDTCihFi"
      },
      "source": [
        "### The Hugging Face Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1DRY90IihFj"
      },
      "source": [
        "### Hugging Face Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UActisZbihFj"
      },
      "source": [
        "### Hugging Face Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs6wkRGnihFk"
      },
      "source": [
        "### Hugging Face Accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39UM3Sg8ihFk"
      },
      "source": [
        "## Main Challenges with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z85U0JxnihFl"
      },
      "source": [
        "## Conclusion"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}